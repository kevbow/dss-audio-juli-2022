{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd3a759e",
   "metadata": {},
   "source": [
    "**Inclass: Convolutional Neural Network**\n",
    "\n",
    "<img src=\"assets/logo.png\" width=\"150\">\n",
    "<br>\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5ecf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa, librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2b6edb",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network\n",
    "\n",
    "Convolutional Neural Network (CNN) saat ini merupakan arsitektur yang umum digunakan untuk menangani **data gambar**. Tetapi seperti yang telah disampaikan sebelumnya, bentuk data yang kita miliki pada hasil pemrosesan data audio mirip dengan bentuk data gambar. Tentunya hal ini membuat metode CNN menjadi relevan untuk digunakan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af9e6ff",
   "metadata": {},
   "source": [
    "## Convolution Concepts\n",
    "\n",
    "Pada modul sebelumnya, kita telah belajar untuk mengklasifikasikan citra tangan-digit ke dalam kelas-kelasnya. Tapi ada masalah:\n",
    "\n",
    "* Menggunakan dense layer, jumlah parameter yang akan dilatih sangat banyak.\n",
    "* Terlalu banyak piksel yang tidak relevan digunakan sebagai input\n",
    "\n",
    "Bagaimana jika kita dapat mengekstrak nilai yang relevan saja dan menghapus semua piksel yang tidak relevan? Dengan begitu jaringan kita akan memiliki fitur yang jauh lebih ringan namun dengan informasi yang relatif sama (atau bahkan lebih baik). Ini adalah saat konvolusi mengambil bagian. Silakan lihat arsitektur jaringan saraf convolutional di bawah ini:\n",
    "\n",
    "![](https://drive.google.com/uc?export=view&id=1B753UW04KdjePCDbTdGr3JeVu01Cmbs4)\n",
    "\n",
    "Berdasarkan ilustrasi, ada empat lapisan yang berbeda:\n",
    "\n",
    "1. **Convolutional layer** untuk mengekstrak fitur penting dari data sebelum dimasukkan ke dalam dense layer. Data yang berbelit-belit mungkin berukuran **lebih kecil** tetapi **lebih kaya** informasi, sehingga menghasilkan pekerjaan yang lebih efektif untuk dense layer.\n",
    "\n",
    "2. **Pooling layer** mengurangi ukuran gambar, hanya mempertahankan piksel yang relevan\n",
    "\n",
    "3. **Flattening layer** mengonversi data gambar dua dimensi menjadi satu dimensi\n",
    "\n",
    "4. **Fully-connected (dense) layer**, jaringan saraf dasar untuk klasifikasi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4879dd3",
   "metadata": {},
   "source": [
    "### 1. Convolutional Layer\n",
    "\n",
    "- Sebuah konvolusi akan **mengekstraksi informasi yang penting** dari data menggunakan **filter**. Filter ini berfungsi seperti filter apa pun di dunia nyata, ia memiliki penggunaan khusus dan memiliki kepekaan terhadap cara yang sangat spesifik. \n",
    "\n",
    "- Misalnya, pikirkan filter UV untuk lensa kamera. Ini akan memblokir sinar UV untuk mengurangi warna biru yang berlebihan dari langit. Semakin banyak sinar UV di lapangan, semakin aktif filter ini untuk memberi tahu Anda bahwa ada lampu UV.\n",
    "![](assets/convolution.gif)\n",
    "\n",
    "- Secara matematis, proses feedforward dari jaringan saraf convolutional disebut **\"cross correlation\"**. Istilah konvolusi berasal dari fungsi turunannya ketika jaringan melakukan backpropagation. Di bawah ini adalah ilustrasi dan rumus matematika tentang bagaimana jaringan melakukan feedforward\n",
    "$$ F \\circ I (x,y) = \\sum_{j=-N}^{N} \\sum_{i=-N}^{N} F(i,j) \\times I(x+i, y+j)$$\n",
    "\n",
    "![convolutional](assets/conv-hackernoon.gif)\n",
    "\n",
    "Penjelasan tentang Image Filtering bisa dilihat di [Google Slides](https://docs.google.com/presentation/d/10UidolXUlmxBesQVaQOEtrunddf7CwnG80wawiZtcxo/edit#slide=id.g115c109ac13_0_47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5d7010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single layer of convolution\n",
    "\n",
    "my_conv_layer = keras.layers.Conv2D(\n",
    "    input_shape=(___,___,___), # (height, width, deep) the deep is 1\n",
    "    filters=___, # jumlah filter/kernel yang digunakan\n",
    "    kernel_size=___, # ukuran dari filter\n",
    "    strides=___, # steps of convolution\n",
    "    padding='___', # DENGAN padding, jadi ukuran output SAMA dengan ukuran input\n",
    "    activation='___', # activation function\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b869ab5a",
   "metadata": {},
   "source": [
    "Parameters ([Documentation of `Conv2D`](https://keras.io/api/layers/convolution_layers/convolution2d/)):\n",
    "\n",
    "- `input_shape`: \n",
    "    + ukuran gambar input dalam format `(height, width, channel)`\n",
    "- `filters`: \n",
    "    + berapa jumlah filter yang akan digunakan untuk menggulung (*convolve*) gambar\n",
    "    + Semakin banyak filter, semakin besar kemungkinan untuk mempelajari fitur yang lebih spesifik\n",
    "    + Jumlah ini setara dengan jumlah neuron dalam lapisan padat (`unit`)\n",
    "- `kernel_size`: \n",
    "    + ukuran untuk setiap filter\n",
    "    + Ukuran yang lebih besar akan menangkap lebih banyak informasi dan kemungkinan besar menggeneralisasi lebih baik daripada yang lebih kecil. \n",
    "    + Tetapi penelitian menunjukkan bahwa **ukuran kernel 3 dan 5** sangat kuat dalam hal kompleksitas algoritme. Tidak ada standar yang ketat dalam menentukan ukuran kernel.\n",
    "    + Praktik terbaik adalah **menggunakan nilai ganjil kecil**. \n",
    "- `strides`: \n",
    "    + Besar langkah dalam memindahkan filter selama proses konvolusi\n",
    "    + Langkah yang besar akan membuat langkah lebih besar dan membuat filter berpotensi melewatkan beberapa piksel yang berarti.\n",
    "- `padding`:\n",
    "    + ditambahkan jika kita ingin ukuran output sama dengan input dengan melakukan beberapa padding sesuai dengan ukuran filter.\n",
    "        - `'valid'`: tanpa padding atau ukuran output tidak sama dengan input\n",
    "        - `'same'`: menggunakan zero-padding pada batas gambar\n",
    "- `activation`: fungsi aktivasi yang akan digunakan setelah input digabungkan\n",
    "    \n",
    "Di bawah ini adalah ilustrasi untuk `padding='same'` pada input 6x6:\n",
    "\n",
    "![padding](assets/zero-padding.png)\n",
    "\n",
    "Mari kita coba lihat kalau diaplikasikan ke data audio kita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790d63c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "file_path = \"data_input/genres_train/blues/blues.00050.wav\"\n",
    "signal, sample_rate = librosa.load(file_path)\n",
    "\n",
    "# Make it as MFCC feature\n",
    "MFCCs = librosa.feature.mfcc(signal, sample_rate, n_fft=2048, hop_length=512, n_mfcc=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e788c03",
   "metadata": {},
   "source": [
    "Coba visualisasikan menggunakan `librosa.display.specshow()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25ab333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize it\n",
    "plt.figure(figsize=(14,6))\n",
    "librosa.display.specshow(MFCCs, sr=sample_rate, hop_length=512, x_axis = 'time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40413fe",
   "metadata": {},
   "source": [
    "Coba visualisasikan menggunakan `heatmap()` dari seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1c9840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize it with seaborn\n",
    "sns.heatmap(MFCCs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb5b6f9",
   "metadata": {},
   "source": [
    "Agar bisa dimasukkan ke convolutional layer, kita akan ubah bentuknya/dimensinya dan dijadikan tipe fload\n",
    "Mari kita ambil gambar pertama, bentuk ulang, dan ubah menjadi float.\n",
    "\n",
    "Pastikan bentuk input dalam konvensi berikut:\n",
    "`(1, HEIGHT, WIDTH, 1)`\n",
    "\n",
    "Kedua nilai 1 di atas diperlukan sebagai bentuk yang diterima oleh `Conv2D`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57314aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape dimension\n",
    "input_mfcc = MFCCs.reshape(1, MFCCs.shape[0], MFCCs.shape[1], 1).astype('float')\n",
    "\n",
    "# apply convolutional layer\n",
    "output_conv = my_conv_layer(input_mfcc)\n",
    "output_conv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652f5fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the result of convolutional output\n",
    "first_filter_output = output_conv[0, :, :, 31]\n",
    "sns.heatmap(first_filter_output, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69edb6aa",
   "metadata": {},
   "source": [
    "### 2. Pooling Layer\n",
    "\n",
    "Ide dari pooling adalah untuk **meringkas dan menyederhanakan** fitur yang convolved dengan melakukan agregasi pada fitur yang convolved. Ingat bahwa kami ingin dense layer diberi dengan fitur kecil namun bermakna. \n",
    "\n",
    "Di bawah ini adalah contoh dari Max Pooling di mana fitur berbelit-belit diringkas menjadi data 2x2.\n",
    "\n",
    "![](assets/maxpool_animation.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73ee912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single layer of pooling\n",
    "\n",
    "my_pool_layer = keras.layers.MaxPooling2D(\n",
    "    pool_size=(___, ___), # size of pooling\n",
    "    strides=___, # steps of pooling\n",
    "    padding='___' # WITHOUT padding\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fefdd2",
   "metadata": {},
   "source": [
    "Parameters ([Documentation of `MaxPooling2D`](https://keras.io/api/layers/pooling_layers/max_pooling2d/):\n",
    "\n",
    "- `pool_size` ekuivalen dengan `kernel_size` pada `Conv2D` yang akan menentukan seberapa besar kolam Anda\n",
    "- `strides` dan `padding` sama seperti pada `Conv2D`\n",
    "\n",
    "> Selain MaxPooling, ada beberapa fungsi bawaan untuk membantu Anda mengurangi fitur tersebut. Mengunjungi [Documentation on Pooling Layers](https://keras.io/api/layers/pooling_layers/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8f856a",
   "metadata": {},
   "source": [
    "#### üîé Knowledge Check: Pooling Output\n",
    "\n",
    "Untuk melihat cara kerja pooling layer, kita dapat memasukkan input acak ke dalamnya. Gunakan bentuk array dari `output_conv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fe0eb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_conv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c48a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input for pooling layer (generate random values)\n",
    "input_pooling = tf.random.normal([1, 7, 647, 32]) # try to change the shape here\n",
    "print(\"INPUT POOLING SHAPE:\", input_pooling.shape)\n",
    "\n",
    "# output for pooling layer\n",
    "output_pooling = my_pool_layer(input_pooling)\n",
    "print(\"OUTPUT POOLING SHAPE:\", output_pooling.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96cc1ae",
   "metadata": {},
   "source": [
    "‚ùìCobalah bereksperimen pada nilai-nilai berikut dengan membuat beberapa perubahan padanya.\n",
    "\n",
    "1. Jika kita mengubah bentuk variabel `input_pooling`, maka ___\n",
    "\n",
    "2. Jika parameter `pool_size` diperbesar, maka ___\n",
    "\n",
    "3. Jika parameter `strides` dinaikkan, maka ___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d94de3a",
   "metadata": {},
   "source": [
    "## Implement CNN in Keras\n",
    "\n",
    "### Load Audio Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491a874d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path):\n",
    "    \"\"\"Loads training dataset from json file.\n",
    "        :param data_path (str): Path to json file containing data\n",
    "        :return X (ndarray): Inputs\n",
    "        :return y (ndarray): Targets\n",
    "    \"\"\"\n",
    "\n",
    "    with open(data_path, \"r\") as fp:\n",
    "        data = json.load(fp)\n",
    "\n",
    "    # convert lists to numpy arrays\n",
    "    X = np.array(data[\"mfcc\"])\n",
    "    y = np.array(data[\"labels\"])\n",
    "\n",
    "    print(\"Data succesfully loaded!\")\n",
    "\n",
    "    return  X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82d40f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "X, y = load_data(\"data.json\")\n",
    "\n",
    "# create train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Check type and shape\n",
    "print('data type \\t: ', type(X_train), type(y_train))\n",
    "print('training size \\t: ', X_train.shape, y_train.shape)\n",
    "print('Test size \\t: ', X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b70d0be",
   "metadata": {},
   "source": [
    "### Creating Model Architecture\n",
    "\n",
    "Tidak seperti data gambar, pada pengolahan data suara tidak terdapat augmentasi dan preprocessing karena nilai yang dipakai adalah nilai koefisien MFCC. Proses yang dilakukan setelah pemisahan data tentu membuat arsitektur CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec686c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(722)\n",
    "np.random.seed(722)\n",
    "tf.random.set_seed(722)\n",
    "\n",
    "# model initiation\n",
    "model_cnn_genres = keras.Sequential()\n",
    "\n",
    "# input layer\n",
    "model_cnn_genres.add(keras.layers.InputLayer(input_shape=(___, ___, ___)))\n",
    "\n",
    "# 1st conv layer\n",
    "model_cnn_genres.add(keras.layers.Conv2D(filters=___, kernel_size=(___, ___), activation='___'))\n",
    "model_cnn_genres.add(keras.layers.MaxPooling2D(pool_size=(___, ___), strides=___, padding='___'))\n",
    "\n",
    "# 2nd conv layer\n",
    "model_cnn_genres.add(keras.layers.Conv2D(filters=___, kernel_size=(___, ___), activation='___'))\n",
    "model_cnn_genres.add(keras.layers.MaxPooling2D(pool_size=(___, ___), strides=___, padding='___'))\n",
    "\n",
    "# flatten output and feed it into dense layer\n",
    "model_cnn_genres.add(keras.layers.Flatten())\n",
    "model_cnn_genres.add(keras.layers.Dense(units=___, activation='___'))\n",
    "model_cnn_genres.add(keras.layers.Dropout(___))\n",
    "\n",
    "# output layer\n",
    "model_cnn_genres.add(keras.layers.Dense(units=___, activation='___'))\n",
    "\n",
    "# compile model\n",
    "optim = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model_cnn_genres.compile(optimizer=___,\n",
    "                        loss='___',\n",
    "                        metrics=['___'])\n",
    "\n",
    "model_cnn_genres.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4eb5c5",
   "metadata": {},
   "source": [
    "### Training Model\n",
    "\n",
    "Setelah arsitektur CNN berhasil dibentuk, kita masuk ke proses training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33d787e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-21T06:39:56.129176Z",
     "start_time": "2022-02-21T06:39:00.839539Z"
    },
    "id": "f33d787e",
    "outputId": "f3d4ab27-71c1-4c30-a7a0-d0adf2f7259b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train model\n",
    "model_history = model_cnn_genres.fit(X_train, y_train, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    batch_size=32, \n",
    "                    epochs=10,\n",
    "                    verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc698ce",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "\n",
    "Kita akan menggunakan data yang sama dengan data evaluasi model NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976680dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to json file that stores MFCCs and genre labels for each processed segment\n",
    "# data_predict_path = \"data_input/data_test.json\"\n",
    "data_predict_path = \"data_test.json\"\n",
    "\n",
    "# load data\n",
    "X_pred, y_pred = load_data(data_predict_path)\n",
    "\n",
    "model_cnn_genres.evaluate(X_pred, y_pred, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2972252a",
   "metadata": {},
   "source": [
    "Kita juga akan membandingkan dengan perhitungan akurasi manual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaeee165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# melakukan prediksi dari data di X_pred lalu mengambil nilai dengan peluang paling tinggi\n",
    "prediction = model_cnn_genres.predict(X_pred, batch_size=32, verbose=1)\n",
    "prediction = prediction.argmax(axis=1)\n",
    "\n",
    "# membuat dataframe untuk menyimpan data hasil prediksi dan data asli\n",
    "compare = pd.DataFrame({'prediction': prediction, \n",
    "                        'observation': y_pred})\n",
    "\n",
    "# membandingkan nilai dari kedua kolom\n",
    "compare['comparison'] = np.where(compare['prediction'] == compare['observation'], True, False)\n",
    "\n",
    "# mengeluarkan perhitungan akurasi dengan menghitung nilai True dari seluruh data\n",
    "manual_accuracy = compare['comparison'].value_counts()[1]/len(prediction)\n",
    "print(\"manual accuracy calculation: \", manual_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0084bdc6",
   "metadata": {},
   "source": [
    "Dan yang terakhir dengan bentuk yang sudah tidak disegmentasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936d3211",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def take_mode(result, num_segments=10):\n",
    "    \"\"\"Function to take mode value from num_segments of data\n",
    "        \n",
    "    --Arguments--\n",
    "        result: \n",
    "            Result from model prediction\n",
    "        num_segments:\n",
    "            The segments that we defined when we save and convert data with mfcc\n",
    "    \"\"\"\n",
    "    new_result = []\n",
    "    i = 0\n",
    "    \n",
    "    for i in range(int((len(result)+1)/num_segments)):\n",
    "        new_result.append(Counter(result[(i*num_segments):((i+1)*num_segments)].tolist()).most_common()[0][0])\n",
    "        i += 1\n",
    "        \n",
    "    return new_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04604c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_y = take_mode(y_pred)\n",
    "new_pred = take_mode(prediction)\n",
    "\n",
    "compare = pd.DataFrame({'prediction': new_pred, \n",
    "                        'observation': new_y})\n",
    "\n",
    "compare['comparison'] = np.where(compare['prediction'] == compare['observation'], True, False)\n",
    "\n",
    "manual_accuracy = compare['comparison'].value_counts()[1]/len(new_pred)\n",
    "manual_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e12b5d",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952a9c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_cnn_genres.save('model/cnn_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88623f0",
   "metadata": {},
   "source": [
    "## Dive Deeper\n",
    "\n",
    "Cobalah buat model dengan arsitektur Convolutional Neural Network yang berbeda, lalu coba juga melakukan hyperparameter tuning pada model yang dibuat. Apakah didapatkan hasil yang lebih baik?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2106e7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee2ddc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dss_audio]",
   "language": "python",
   "name": "conda-env-dss_audio-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
